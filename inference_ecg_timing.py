#!/usr/bin/env python3
"""
ECG + Timing Features Inference Script

This script:
1. Loads a random ECG from the dataset
2. Extracts timing features using NeuroKit2
3. Passes combined input through trained sparse autoencoder
4. Shows which features activate most with clinical interpretations
5. Plots ECG with timing annotations and feature activations

Usage: python inference_ecg_timing.py [--model_path MODEL.pth]
"""

import argparse
import random
import json
from pathlib import Path
import numpy as np
import torch
import matplotlib.pyplot as plt

try:
    import neurokit2 as nk
except ImportError:
    raise SystemExit("Install NeuroKit2: pip install neurokit2")

from data_loader import PTBXLDataset
from sparse_autoencoder import GatedSparseAutoencoder
from tools.timing_extractor import get_timing_extractor


def load_feature_interpretations(filename: str = 'feature_interpretations.json') -> dict:
    """
    Load feature interpretations generated by analyze_features.py.
    
    Args:
        filename: Path to the feature interpretations JSON file
        
    Returns:
        Dictionary mapping feature_idx to interpretation data
    """
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            interpretations = json.load(f)
        
        # Convert to dict indexed by feature_idx for quick lookup
        feature_dict = {}
        for item in interpretations:
            feature_dict[item['feature_idx']] = item
            
        print(f"Loaded interpretations for {len(feature_dict)} features")
        return feature_dict
        
    except FileNotFoundError:
        print(f"Warning: Feature interpretations file '{filename}' not found.")
        print("Run analyze_features.py first to generate clinical interpretations.")
        return {}
    except Exception as e:
        print(f"Error loading feature interpretations: {e}")
        return {}


def extract_timing_features_with_fiducials(ecg_signal: np.ndarray, sampling_rate: int = 100) -> dict:
    """Extract timing features with fiducials using unified extractor."""
    try:
        # Use the unified timing extractor's real-time method
        extractor = get_timing_extractor(use_cache=False)  # Force real-time extraction
        features = extractor._extract_timing_features_realtime(ecg_signal, sampling_rate)
        
        # Also extract fiducials for visualization using NeuroKit2
        ecg_1d = ecg_signal[:, 1] if ecg_signal.ndim == 2 and ecg_signal.shape[1] > 1 else ecg_signal.flatten()
        
        signals, info = nk.ecg_process(ecg_1d, sampling_rate=sampling_rate)
        r_peaks = info["ECG_R_Peaks"]
        
        fiducials = {}
        if len(r_peaks) >= 2:
            # Delineate waves for fiducial points
            _, waves = nk.ecg_delineate(signals["ECG_Clean"], r_peaks, sampling_rate=sampling_rate)
            
            def get_points(key):
                pts = waves.get(key, [])
                return np.array(pts)[~np.isnan(pts)].astype(int) if pts is not None else np.array([])
            
            p_onsets = get_points("ECG_P_Onsets")
            q_peaks = get_points("ECG_Q_Peaks") 
            s_peaks = get_points("ECG_S_Peaks")
            t_offsets = get_points("ECG_T_Offsets")
            
            # Get fiducials for first beat
            r_peak = r_peaks[0]
            p_onset = p_onsets[p_onsets < r_peak][-1] if len(p_onsets[p_onsets < r_peak]) > 0 else None
            q_peak = q_peaks[np.abs(q_peaks - r_peak) <= 25][0] if len(q_peaks[np.abs(q_peaks - r_peak) <= 25]) > 0 else r_peak
            s_peak = s_peaks[np.abs(s_peaks - r_peak) <= 50][0] if len(s_peaks[np.abs(s_peaks - r_peak) <= 50]) > 0 else r_peak
            t_offset = t_offsets[t_offsets > r_peak][0] if len(t_offsets[t_offsets > r_peak]) > 0 else None
            
            fiducials = {
                'p_onset': p_onset,
                'q_peak': q_peak,
                'r_peak': r_peak,
                's_peak': s_peak,
                't_offset': t_offset
            }
        
        return {
            'features': features,
            'fiducials': fiducials,
            'success': True
        }
        
    except Exception as e:
        print(f"Timing extraction failed: {e}")
        return {
            'features': np.array([150.0, 80.0, 400.0, 70.0]),
            'fiducials': {},
            'success': False
        }


def plot_ecg_with_features(ecg_signal: np.ndarray, timing_result: dict, 
                          feature_activations: np.ndarray, top_features: list,
                          report: str, feature_interpretations: dict = None, 
                          sampling_rate: int = 100, save_path: str = None):
    """Plot ECG with timing annotations and feature activations."""
    time_axis = np.arange(ecg_signal.shape[0]) / sampling_rate
    
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))
    
    # Plot ECG with timing annotations
    ax1.plot(time_axis, ecg_signal, 'b-', linewidth=0.8, label='ECG Lead II')
    
    if timing_result['success']:
        fiducials = timing_result['fiducials']
        colors = {'p_onset': 'green', 'q_peak': 'red', 'r_peak': 'darkred', 
                 's_peak': 'red', 't_offset': 'orange'}
        
        # Mark fiducial points
        for name, sample_idx in fiducials.items():
            if sample_idx is not None:
                time_s = sample_idx / sampling_rate
                color = colors.get(name, 'purple')
                ax1.axvline(time_s, color=color, linestyle='--', alpha=0.7)
                ax1.plot(time_s, ecg_signal[sample_idx], 'o', color=color, 
                        markersize=6, label=name.upper())
        
        # Highlight intervals
        if fiducials['p_onset'] is not None and fiducials['q_peak'] is not None:
            start_t = fiducials['p_onset'] / sampling_rate
            end_t = fiducials['q_peak'] / sampling_rate
            ax1.axvspan(start_t, end_t, alpha=0.2, color='green', label='PR')
        
        if fiducials['q_peak'] is not None and fiducials['s_peak'] is not None:
            start_t = fiducials['q_peak'] / sampling_rate
            end_t = fiducials['s_peak'] / sampling_rate
            ax1.axvspan(start_t, end_t, alpha=0.2, color='red', label='QRS')
        
        if fiducials['q_peak'] is not None and fiducials['t_offset'] is not None:
            start_t = fiducials['q_peak'] / sampling_rate
            end_t = fiducials['t_offset'] / sampling_rate
            ax1.axvspan(start_t, end_t, alpha=0.1, color='orange', label='QT')
    
    ax1.set_xlabel('Time (s)')
    ax1.set_ylabel('Amplitude (mV)')
    ax1.set_title('ECG with Timing Intervals')
    ax1.grid(True, alpha=0.3)
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # Plot feature activations
    ax2.bar(range(len(feature_activations)), feature_activations, alpha=0.7)
    ax2.set_xlabel('Feature Index')
    ax2.set_ylabel('Activation Strength')
    ax2.set_title('Sparse Autoencoder Feature Activations')
    ax2.grid(True, alpha=0.3)
    
    # Highlight top features (without legend to avoid overlap)
    for i, (feat_idx, activation) in enumerate(top_features):
        bar = ax2.bar(feat_idx, activation, color='red', alpha=0.8)
        # Add feature index as text annotation on the bar
        ax2.text(feat_idx, activation + 0.1, f'F{feat_idx}', 
                ha='center', va='bottom', fontsize=8, fontweight='bold')
    
    # Remove legend as we'll show feature info in text box
    # ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    
    # Add timing features and report as text
    features = timing_result['features']
    text_info = f"Timing Features:\\n"
    text_info += f"PR: {features[0]:.0f} ms\\n"
    text_info += f"QRS: {features[1]:.0f} ms\\n"
    text_info += f"QT: {features[2]:.0f} ms\\n"
    text_info += f"HR: {features[3]:.0f} bpm\\n\\n"
    
    # Add feature key words and summaries
    if top_features:
        text_info += f"Top {len(top_features)} Activating Features (Key Word):\\n"
        for i, (feat_idx, activation) in enumerate(top_features):
            key_word = "No key word"
            summary = ""
            if feature_interpretations and feat_idx in feature_interpretations:
                interp_data = feature_interpretations[feat_idx]
                key_word = interp_data.get('key_word', "No key word")
                summary = interp_data.get('summary', "")
            text_info += f"F{feat_idx}: {activation:.3f} | {key_word} | {summary}\\n"
        text_info += "\\n"
    
    text_info += f"Report: {report[:50]}..."

    # Display feature info in a wide, wrapped textbox below the bar plot
    import textwrap
    feature_lines = text_info.split("\n")
    wrapped_lines = []
    for line in feature_lines:
        wrapped_lines.extend(textwrap.wrap(line, width=90, break_long_words=False, replace_whitespace=False) or [""])
    wrapped_text = "\n".join(wrapped_lines)
    # Place textbox just below the x-axis, spanning the width
    ax2.text(
        0.01, -0.25, wrapped_text,
        transform=ax2.transAxes,
        fontsize=8,
        fontfamily='monospace',
        va='top', ha='left',
        bbox=dict(facecolor='white', edgecolor='gray', boxstyle='round,pad=0.4'),
        linespacing=1.5,
        clip_on=False
    )
    
    # Add a large textbox below the plots with summary and key word for top features
    if top_features and feature_interpretations:
        interp_texts = []
        for feat_idx, activation in top_features:
            interp = feature_interpretations.get(feat_idx, {})
            key_word = interp.get('key_word', "No key word")
            summary = interp.get('summary', "")
            header = f"Feature {feat_idx} ({key_word}):"
            interp_texts.append(header)
            interp_texts.append(summary)
            interp_texts.append("")
        interp_texts = interp_texts[:75]
        big_text = '\n'.join(interp_texts)
        from matplotlib import gridspec
        gs = fig.add_gridspec(3, 1, height_ratios=[1, 1, 1.2])
        ax1.set_position(gs[0].get_position(fig))
        ax2.set_position(gs[1].get_position(fig))
        axbox = fig.add_subplot(gs[2])
        axbox.axis('off')
        import textwrap
        wrapped_big_text = '\n'.join(textwrap.wrap(big_text, width=140, break_long_words=False, replace_whitespace=False))
        axbox.text(0, 1, wrapped_big_text, va='top', ha='left', fontsize=9, fontfamily='monospace', linespacing=1.3)
        plt.subplots_adjust(hspace=0.35, bottom=0.08, top=0.96)
    else:
        plt.tight_layout()
    # Save figure if path provided
    if save_path:
        from pathlib import Path
        plots_dir = Path("plots")
        plots_dir.mkdir(exist_ok=True)
        plt.savefig(plots_dir / save_path, dpi=300, bbox_inches='tight')
        print(f"Figure saved to plots/{save_path}")
    plt.show()


def main():
    parser = argparse.ArgumentParser(description="ECG + Timing Features Inference")
    parser.add_argument("--model_path", default="checkpoints/best_model.pth",
                       help="Path to trained model")
    parser.add_argument("--data_path", default="physionet.org/files/ptb-xl/1.0.3/",
                       help="PTB-XL dataset path")
    parser.add_argument("--n_samples", type=int, default=3,
                       help="Number of random samples to analyze")
    parser.add_argument("--top_k", type=int, default=5,
                       help="Number of top features to highlight")
    parser.add_argument("--interpretations", default="feature_interpretations.json",
                       help="Path to feature interpretations JSON file")
    
    args = parser.parse_args()
    
    # Load dataset
    dataset = PTBXLDataset(args.data_path, sampling_rate=100, normalize=False, max_samples=100)
    print(f"Loaded {len(dataset)} ECG samples")
    
    # Load feature interpretations
    feature_interpretations = load_feature_interpretations(args.interpretations)
    
    # Load the trained model
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # Load checkpoint with safe globals for PyTorch 2.6 compatibility
    with torch.serialization.safe_globals([
        np._core.multiarray.scalar, 
        np.dtype, 
        np.ndarray,
        np.float32,
        np.float64,
        np.int32,
        np.int64,
        np.dtypes.Int64DType,
        np.dtypes.Float64DType,
        np.dtypes.Int32DType,
        np.dtypes.Float32DType
    ]):
        checkpoint = torch.load(args.model_path, map_location='cpu')
    
    # Extract model configuration
    config = checkpoint.get('model_config', {})
    
    # Calculate ECG and timing dimensions from total input dimension
    total_input_dim = config.get('input_dim', 12004)  # 12000 ECG + 4 timing features
    ecg_input_dim = total_input_dim - 4
    timing_features_dim = 4
    
    # Import here to avoid circular import
    from sparse_autoencoder import GatedSparseAutoencoder
    
    # Create model with loaded configuration
    model = GatedSparseAutoencoder(
        ecg_input_dim=ecg_input_dim,
        timing_features_dim=timing_features_dim,
        hidden_dims=config.get('hidden_dims', [2048, 1024, 512]),
        latent_dim=config.get('latent_dim', 256),
        sparsity_weight=config.get('sparsity_weight', 0.01)
    )
    
    # Load model state
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    model.to(device)
    
    print(f"Model loaded, using device: {device}")
    
    # Analyze random samples
    random.seed(42)
    indices = random.sample(range(len(dataset)), min(args.n_samples, len(dataset)))
    
    for i, idx in enumerate(indices):
        sample = dataset[idx]
        row_meta = dataset.metadata.iloc[sample['idx']]
        
        print(f"\\n[{i+1}/{args.n_samples}] ECG ID: {row_meta.name}")
        
        # Get ECG signal
        ecg_signal_2d = sample['signal'].numpy()
        ecg_signal_flat = sample['signal_flat'].numpy()
        
        # Extract timing features
        timing_result = extract_timing_features_with_fiducials(ecg_signal_2d, sampling_rate=100)
        timing_features = timing_result['features']
        
        print(f"Timing features: PR={timing_features[0]:.0f}, QRS={timing_features[1]:.0f}, "
              f"QT={timing_features[2]:.0f}, HR={timing_features[3]:.0f}")
        
        # Combine ECG and timing features
        combined_input = np.concatenate([ecg_signal_flat, timing_features])
        combined_tensor = torch.FloatTensor(combined_input).unsqueeze(0).to(device)
        
        # Forward pass through model
        with torch.no_grad():
            _, latent = model(combined_tensor)
            feature_activations = latent.squeeze(0).cpu().numpy()
        
        # Find top activating features
        top_indices = np.argsort(np.abs(feature_activations))[-args.top_k:][::-1]
        top_features = [(idx, feature_activations[idx]) for idx in top_indices]
        
        print(f"Top {args.top_k} activating features:")
        for feat_idx, activation in top_features:
            interpretation_info = ""
            if feat_idx in feature_interpretations:
                interp = feature_interpretations[feat_idx]
                key_word = interp.get('key_word', '')
                summary = interp.get('summary', '')
                interpretation_info = f" | {key_word} | {summary[:60]}{'...' if len(summary) > 60 else ''}"
            print(f"  Feature {feat_idx}: {activation:.4f}{interpretation_info}")

        # Get report
        report = str(row_meta.get('report', '')).strip()
        print(f"Clinical report: {report}")
        
        # Plot results
        ecg_1d = ecg_signal_2d[:, 1] if ecg_signal_2d.shape[1] > 1 else ecg_signal_2d[:, 0]
        save_filename = f"ecg_analysis_{row_meta.name}_{i+1}.png"
        plot_ecg_with_features(ecg_1d, timing_result, feature_activations, 
                              top_features, report, feature_interpretations, 
                              sampling_rate=100, save_path=save_filename)
        
        print("-" * 60)


if __name__ == "__main__":
    main()
